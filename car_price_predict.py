# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EZodVWZs0ZVgjTIRRl3ykvie-ixCNDtA
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

car_df = pd.read_csv('/content/Car_Purchasing_Data.csv', encoding = 'ISO-8859-1')

car_df

sns.pairplot(car_df)

X = car_df.drop(['Customer Name' , 'Customer e-mail' , 'Country' , 'Car Purchase Amount'] , axis = 1)

y = car_df['Car Purchase Amount']

X.shape

y.shape

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_x = scaler.fit_transform(X)
scaler.data_max_
scaler.data_min_

y = y.values.reshape(-1,1)
scaled_y = scaler.fit_transform(y)
scaler.data_max_
scaler.data_min_

from sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test = train_test_split(scaled_x,scaled_y,test_size=0.25)

x_test.shape
x_test.shape
y_train.shape
y_test.shape

import tensorflow.keras
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(40 , input_dim = 5, activation= 'relu'))
model.add(Dense(40 , activation='relu'))
model.add(Dense(1,activation='linear'))

model.summary()



model.compile(optimizer='adam', loss='mean_squared_error')
epochs_hist = model.fit(x_train ,
                        y_train ,
                        epochs=100 ,
                        batch_size = 50,
                        verbose = 1,
                        validation_split= 0.2)



epochs_hist.history.keys()

plt.plot(epochs_hist.history['loss'])
plt.plot(epochs_hist.history['val_loss'])
plt.title('Model Loss Progress During Training')
plt.ylabel('Traning and Validation loss')
plt.xlabel('Epoch number')
plt.legend(['Training Loss' ,'Validation Loss'])

# Gender, Age, Annual Salary, Credit card debt , net worth
x_test = np.array([[1,50,50000,10000,600000]])
y_predict = model.predict(x_test)
print('Expected Purchase Amount', y_predict)

